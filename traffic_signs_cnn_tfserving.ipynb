{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Signs Recognition Project with Tensorflow Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded from Kaggle __[here](https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign?select=Train.csv)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = '/path/to/dataset/directory/'\n",
    "\n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = cur_path + 'Train/' + str(i) + '/*'\n",
    "    images = glob.glob(path)\n",
    "    for im in images:\n",
    "        try:\n",
    "            image = cv2.imread(im)\n",
    "            image = cv2.resize(image, (30,30))\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "\n",
    "#Converting lists into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(data.shape, labels.shape)\n",
    "#Splitting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#Converting the labels into one hot encoding\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model So That Inferences Can be Done Just Via Image Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/path/to/model/traffic_signs_model'\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting graphs for accuracy \n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Tensorflow Serving to Serve the Model (For Linux or Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# We need sudo prefix if not on a Google Colab.\n",
    "if 'google.colab' not in sys.modules:\n",
    "  SUDO_IF_NEEDED = 'sudo'\n",
    "else:\n",
    "  SUDO_IF_NEEDED = ''\n",
    "\n",
    "\n",
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -\n",
    "!{SUDO_IF_NEEDED} apt update\n",
    "\n",
    "\n",
    "!{SUDO_IF_NEEDED} apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_model_server --port=8500 --rest_api_port=8598 --model_name=traffic_signs_model --model_base_path=\"/path/to/model/traffic_signs_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "cur_path = '/path/to/dataset/directory/'\n",
    "\n",
    "path = cur_path + 'Test/*'\n",
    "images = glob.glob(path)\n",
    "\n",
    "#Retrieving the images and their labels\n",
    "for im in images[:5]:\n",
    "    try:\n",
    "        image = cv2.imread(im)\n",
    "        image = cv2.resize(image, (30,30))\n",
    "        data.append(image)\n",
    "    except:\n",
    "        print(\"Error loading image\")\n",
    "    \n",
    "\n",
    "#Converting lists into numpy arrays\n",
    "test_imgs = np.array(data)\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"inputs\": test_imgs.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://127.0.0.1:8598/v1/models/traffic_signs_model/versions/1:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['outputs']\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to label all traffic signs class.\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in predictions:    \n",
    "    print(np.argmax(pred), classes[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Predictions along with the Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, img in zip(predictions, test_imgs):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Class ' + str(np.argmax(pred)) + ' : ' + classes[np.argmax(pred)])\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model on the Complete Testing Dataset and Compare Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = pd.read_csv('/path/to/dataset/directory/Test.csv')\n",
    "\n",
    "labels = y_test[\"ClassId\"].values\n",
    "\n",
    "data = []\n",
    "cur_path = '/path/to/dataset/directory/'\n",
    "\n",
    "path = cur_path + 'Test/*'\n",
    "images = glob.glob(path)\n",
    "\n",
    "#Retrieving the images and their labels\n",
    "for im in images[:5]:\n",
    "    try:\n",
    "        image = cv2.imread(im)\n",
    "        image = cv2.resize(image, (30,30))\n",
    "        data.append(image)\n",
    "    except:\n",
    "        print(\"Error loading image\")\n",
    "    \n",
    "\n",
    "#Converting lists into numpy arrays\n",
    "test_imgs = np.array(data)\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"inputs\": test_imgs.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://127.0.0.1:8598/v1/models/traffic_signs_model/versions/1:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['outputs']\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "predicted_classes = []\n",
    "for pred in predictions:    \n",
    "    predicted_classes.append(np.argmax(pred))\n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
